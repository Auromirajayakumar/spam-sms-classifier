{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eaefb03-c374-47c3-8b3d-b5e4c236c693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Accuracy Score: 0.9614349775784753\n",
      "\n",
      "ðŸ“Š Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       965\n",
      "           1       1.00      0.71      0.83       150\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.98      0.86      0.91      1115\n",
      "weighted avg       0.96      0.96      0.96      1115\n",
      "\n",
      "\n",
      "ðŸ“‰ Confusion Matrix:\n",
      " [[965   0]\n",
      " [ 43 107]]\n",
      "\n",
      "ðŸ“¬ Sample Prediction: Ham\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Œ Step 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Download stopwords (only once)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# ðŸ“Œ Step 2: Load Dataset\n",
    "df = pd.read_csv('dataset/spam.csv', encoding='latin-1')[['v1', 'v2']]\n",
    "df.columns = ['label', 'text']  # Rename columns for clarity\n",
    "df.head()\n",
    "\n",
    "# ðŸ“Œ Step 3: Text Cleaning Function\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    tokens = text.split()\n",
    "    cleaned = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(cleaned)\n",
    "\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# ðŸ“Œ Step 4: Encode Labels\n",
    "df['label_num'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# ðŸ“Œ Step 5: TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df['cleaned_text'])\n",
    "y = df['label_num']\n",
    "\n",
    "# ðŸ“Œ Step 6: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ðŸ“Œ Step 7: Model Training\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ðŸ“Œ Step 8: Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"âœ… Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nðŸ“Š Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nðŸ“‰ Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# ðŸ“Œ Step 9: Test a Custom SMS\n",
    "sample = [\"Congratulations! You've won a free ticket. Call now!\"]\n",
    "sample_cleaned = tfidf.transform([clean_text(sample[0])])\n",
    "prediction = model.predict(sample_cleaned)\n",
    "print(\"\\nðŸ“¬ Sample Prediction:\", \"Spam\" if prediction[0] == 1 else \"Ham\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3533f9-6d36-4b78-b650-c25fc5744a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a241bb2c-0966-4284-b208-09bd0b812b54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
