import pandas as pd
import string
import nltk
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
import pickle

# Download stopwords
nltk.download('stopwords')

# Load dataset
df = pd.read_csv("spam.csv", encoding='latin-1')[['v1', 'v2']]
df.columns = ['label', 'text']

# Preprocessing
def clean_text(text):
    text = text.lower()
    text = ''.join([char for char in text if char not in string.punctuation])
    text = ' '.join([word for word in text.split() if word not in stopwords.words('english')])
    return text

df['cleaned'] = df['text'].apply(clean_text)

# Encode labels
df['label_num'] = df['label'].map({'ham': 0, 'spam': 1})

# Build pipeline
model = Pipeline([
    ('tfidf', TfidfVectorizer()),
    ('nb', MultinomialNB())
])

# Train model
model.fit(df['cleaned'], df['label_num'])

# Save model
with open("model.pkl", "wb") as f:
    pickle.dump(model, f)

print("âœ… Model trained and saved as model.pkl")
